# handlers/learning.py
import random
import aiofiles
import logging
import io
import os
import base64
from datetime import datetime
from telegram import (
    Update,
    InputMediaPhoto,
    InputMediaVideo,
    InputMediaAudio,
    InputMediaDocument,
    InputMediaAnimation,   # –¥–æ–¥–∞–Ω–æ –¥–ª—è GIF
)
from telegram.ext import ContextTypes
from telegram.error import BadRequest
from utils.keyboards import (
    learning_range_keyboard, learning_order_keyboard,
    build_options_markup, get_progress_bar
)
from utils.formatting import format_question_text
from utils.i18n import t

logger = logging.getLogger("test_bot.learning")

ENABLE_MEDIA = os.getenv("ENABLE_MEDIA", "1") == "1"

# ===== –ù–æ–≤—ñ –ø—Ä–∞–≤–∏–ª–∞ –≤—ñ–¥–ø—Ä–∞–≤–∫–∏ –º–µ–¥—ñ–∞ =====
# –ó–æ–±—Ä–∞–∂–µ–Ω–Ω—è inline: .jpg .jpeg .png .webp ‚Üí —è–∫ —Ñ–æ—Ç–æ; .gif ‚Üí —è–∫ –∞–Ω—ñ–º–∞—Ü—ñ—è
# –í—ñ–¥–µ–æ inline: —Ç—ñ–ª—å–∫–∏ .mp4 ‚Üí –≤—ñ–¥–µ–æ; —ñ–Ω—à—ñ –≤—ñ–¥–µ–æ ‚Üí –¥–æ–∫—É–º–µ–Ω—Ç
# –ê—É–¥—ñ–æ inline: .mp3 .wav .ogg .m4a .aac .flac ‚Üí —è–∫ –∞—É–¥—ñ–æ
_IMG_EXT_PHOTO = {".jpg", ".jpeg", ".png", ".webp"}
_IMG_EXT_ANIM = {".gif"}
_AUDIO_EXTS = {".mp3", ".wav", ".ogg", ".m4a", ".aac", ".flac"}
_VIDEO_INLINE = {".mp4"}

def _placeholder_png_bytes() -> bytes:
    """–ü–æ–≤–µ—Ä—Ç–∞—î –±–∞–π—Ç–∏ PNG-–∑–∞–≥–ª—É—à–∫–∏ (1x1)."""
    b64 = (
        b'iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAA'
        b'AAC0lEQVR42mP8/x8AAwMCAO+XU2sAAAAASUVORK5CYII='
    )
    return base64.b64decode(b64)

async def _load_file_bytes(path: str | None) -> bytes | None:
    """–ß–∏—Ç–∞—î —Ñ–∞–π–ª —É –ø–∞–º‚Äô—è—Ç—å. –Ø–∫—â–æ –Ω–µ–º–∞—î/–ø–æ–º–∏–ª–∫–∞ ‚Äî None."""
    if not path:
        return None
    try:
        async with aiofiles.open(path, "rb") as f:
            return await f.read()
    except Exception as e:
        logger.debug("[LEARN][MEDIA] read failed %s: %s", path, e)
        return None

def _bio_with_name(data: bytes, filename: str) -> io.BytesIO:
    """BytesIO –∑ —ñ–º–µ–Ω–µ–º ‚Äî Telegram –ª—é–±–∏—Ç—å –º–∞—Ç–∏ filename –¥–ª—è –º–µ–¥—ñ–∞."""
    bio = io.BytesIO(data)
    bio.name = filename
    return bio

def _pick_media_for_question(q: dict) -> tuple[str, str | None]:
    """
    –í–∏–∑–Ω–∞—á–∞—î —Ç–∏–ø –º–µ–¥—ñ–∞ –ø–∏—Ç–∞–Ω–Ω—è.
    –ó–∞ –Ω–∞—è–≤–Ω–æ—Å—Ç—ñ ENABLE_MEDIA=True –ø—Ä—ñ–æ—Ä–∏—Ç–µ—Ç: video > image > audio > document.
    –ü—Ä–∏ ENABLE_MEDIA=False –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ —Ç—ñ–ª—å–∫–∏ image (–∞–±–æ none).
    –ü–æ–≤–µ—Ä—Ç–∞—î (media_type, abs_path_or_None) –¥–µ media_type ‚àà {image, video, audio, document, none}.
    """
    if ENABLE_MEDIA:
        if q.get("video"):
            return "video", q["video"]
        if q.get("image"):
            return "image", q["image"]
        if q.get("audio"):
            return "audio", q["audio"]
        if q.get("document"):
            return "document", q["document"]
        return "none", None
    else:
        if q.get("image"):
            return "image", q["image"]
        return "none", None

# ===================== –ì–í–ê–†–î–ò –°–¢–ê–ù–£ =====================

def _is_learning_flow(context: ContextTypes.DEFAULT_TYPE) -> bool:
    """
    –ú–∏ —É —Ñ–ª–æ—É—ñ –Ω–∞–≤—á–∞–Ω–Ω—è, –∫–æ–ª–∏ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á —â–æ–π–Ω–æ –∑–∞–π—à–æ–≤ —É ¬´–†–µ–∂–∏–º –Ω–∞–≤—á–∞–Ω–Ω—è¬ª
    —Ç–∞ –æ–±–∏—Ä–∞—î –¥—ñ–∞–ø–∞–∑–æ–Ω/–ø–æ—Ä—è–¥–æ–∫, –∞–±–æ –≤–∂–µ –ø—Ä–æ—Ö–æ–¥–∏—Ç—å –ø–∏—Ç–∞–Ω–Ω—è.
    """
    mode = context.user_data.get("mode")
    return mode == "learning"

def _is_waiting_custom_range(context: ContextTypes.DEFAULT_TYPE) -> bool:
    return bool(context.user_data.get("awaiting_custom_range"))

# ===================== –û–±—Ä–æ–±–Ω–∏–∫–∏ –≤–∏–±–æ—Ä—É –¥—ñ–∞–ø–∞–∑–æ–Ω—É/–ø–æ—Ä—è–¥–∫—É =====================

async def handle_learning_range(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """
    –û–±—Ä–æ–±–Ω–∏–∫ –∫–ª—ñ–∫—ñ–≤ –ø–æ –¥—ñ–∞–ø–∞–∑–æ–Ω—É —Ç–∞ ¬´–ù–∞–∑–∞–¥¬ª —É –ú–û–î–Ü –Ω–∞–≤—á–∞–Ω–Ω—è.
    –Ü–ì–ù–û–†–£–Ñ ¬´–ù–∞–∑–∞–¥¬ª —Ç–∞ –±—É–¥—å-—è–∫–∏–π –≤–≤—ñ–¥, —è–∫—â–æ –º–∏ –ù–ï —É –Ω–∞–≤—á–∞–ª—å–Ω–æ–º—É —Ñ–ª–æ—É—ñ ‚Äî —â–æ–± –Ω–µ –¥—É–±–ª—é–≤–∞—Ç–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ
    –∑ –±—Ä–∞—É–∑–µ—Ä–æ–º —Ä–æ–∑–¥—ñ–ª—ñ–≤ —á–∏ —ñ–Ω—à–∏–º–∏ –µ–∫—Ä–∞–Ω–∞–º–∏.
    """
    text = (update.message.text or "").strip()

    # –Ø–∫—â–æ —Ü–µ ¬´–ù–∞–∑–∞–¥¬ª, –∞–ª–µ –º–∏ –Ω–µ —É –Ω–∞–≤—á–∞–Ω–Ω—ñ ‚Äî —ñ–≥–Ω–æ—Ä—É—î–º–æ (–¥–∞—î–º–æ —ñ–Ω—à–∏–º —Ö–µ–Ω–¥–ª–µ—Ä–∞–º –æ–±—Ä–æ–±–∏—Ç–∏)
    if text in {"üîô –ù–∞–∑–∞–¥", "‚¨ÖÔ∏è –ù–∞–∑–∞–¥"} and not _is_learning_flow(context):
        logger.info("[LEARN] Back pressed outside learning flow ‚Äî ignore")
        return

    # –ö–ª—ñ–∫ –ø–æ –¥—ñ–∞–ø–∞–∑–æ–Ω—É –∞–±–æ ¬´–í–ª–∞—Å–Ω–∏–π –¥—ñ–∞–ø–∞–∑–æ–Ω¬ª –º–∏ –ø—Ä–∏–π–º–∞—î–º–æ –ª–∏—à–µ —É –Ω–∞–≤—á–∞–ª—å–Ω–æ–º—É —Ñ–ª–æ—É—ñ
    if not _is_learning_flow(context) and not _is_waiting_custom_range(context):
        logger.info("[LEARN] Ignored input outside learning flow: %r", text)
        return

    if "add_question" in context.user_data:
        logger.info(f"[LEARN] Skip: add_question active for user={update.effective_user.id}")
        return

    lang = context.bot_data.get("lang", "uk")
    range_text = text
    total_questions = context.user_data.get("total_questions", 0)

    logger.info(f"[LEARN] handle_learning_range user={update.effective_user.id} text='{range_text}' total={total_questions}")

    if range_text in {"üîô –ù–∞–∑–∞–¥", "‚¨ÖÔ∏è –ù–∞–∑–∞–¥"}:
        from utils.keyboards import main_menu
        await update.message.reply_text(
            t(lang, "menu_main", test=context.user_data.get("current_test", "–¢–µ—Å—Ç")),
            reply_markup=main_menu()
        )
        logger.info(f"[LEARN] Back to main menu")
        return

    if range_text == "üî¢ –í–ª–∞—Å–Ω–∏–π –¥—ñ–∞–ø–∞–∑–æ–Ω":
        context.user_data["awaiting_custom_range"] = True
        from telegram import ReplyKeyboardMarkup, KeyboardButton
        await update.message.reply_text(
            t(lang, "learning_set_custom", count=total_questions),
            reply_markup=ReplyKeyboardMarkup([[KeyboardButton("üîô –ù–∞–∑–∞–¥")]], resize_keyboard=True)
        )
        logger.info(f"[LEARN] Awaiting custom range")
        return

    try:
        parts = range_text.split("-")
        if len(parts) != 2:
            raise ValueError("bad format")
        start, end = map(int, parts)
        start = max(1, min(start, total_questions))
        end = max(1, min(end, total_questions))
        if start > end:
            start, end = end, start

        context.user_data["learning_range"] = (start, end)
        context.user_data["mode"] = "learning"

        await update.message.reply_text(
            t(lang, "learning_range_set", start=start, end=end),
            reply_markup=learning_order_keyboard()
        )
        logger.info(f"[LEARN] Range set {start}-{end} (mode=learning)")
    except Exception as e:
        logger.warning(f"[LEARN] Range parse error: '{range_text}' err={e}")
        await update.message.reply_text(t(lang, "range_invalid"))

async def handle_custom_range(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """
    –ü—Ä–∏–π–º–∞—î–º–æ ¬´–∫–∞—Å—Ç–æ–º–Ω–∏–π¬ª –¥—ñ–∞–ø–∞–∑–æ–Ω –ª–∏—à–µ –∫–æ–ª–∏ –º–∏ —Å–ø—Ä–∞–≤–¥—ñ –ô–û–ì–û –æ—á—ñ–∫—É—î–º–æ.
    –Ü–Ω–∞–∫—à–µ ‚Äî —ñ–≥–Ω–æ—Ä—É—î–º–æ (—â–æ–± –Ω–µ –ø–µ—Ä–µ—Ö–æ–ø–ª—é–≤–∞—Ç–∏ –¥–æ–≤—ñ–ª—å–Ω–∏–π —Ç–µ–∫—Å—Ç —Ç–∞ ¬´–ù–∞–∑–∞–¥¬ª –ø–æ–∑–∞ —Ñ–ª–æ—É).
    """
    if not _is_waiting_custom_range(context):
        logger.info("[LEARN] custom range text outside waiting state ‚Äî ignore")
        return

    if "add_question" in context.user_data:
        logger.info(f"[LEARN] Skip custom range: add_question active user={update.effective_user.id}")
        return

    lang = context.bot_data.get("lang", "uk")
    txt = (update.message.text or "").strip()
    total_questions = context.user_data.get("total_questions", 0)

    logger.info(f"[LEARN] handle_custom_range user={update.effective_user.id} text='{txt}' total={total_questions}")

    if txt in {"üîô –ù–∞–∑–∞–¥", "‚¨ÖÔ∏è –ù–∞–∑–∞–¥"}:
        context.user_data.pop("awaiting_custom_range", None)
        await update.message.reply_text(
            "–û–±–µ—Ä–∏ –¥—ñ–∞–ø–∞–∑–æ–Ω:",
            reply_markup=learning_range_keyboard(total_questions)
        )
        logger.info("[LEARN] Back to range keyboard")
        return

    try:
        parts = txt.split("-")
        if len(parts) != 2:
            raise ValueError("bad format")
        start, end = map(int, parts)
        if start < 1 or end > total_questions:
            await update.message.reply_text(t(lang, "range_bounds", count=total_questions))
            logger.info(f"[LEARN] Out of bounds: {start}-{end} of {total_questions}")
            return
        if start > end:
            start, end = end, start

        context.user_data["learning_range"] = (start, end)
        context.user_data.pop("awaiting_custom_range", None)
        context.user_data["mode"] = "learning"

        await update.message.reply_text(
            t(lang, "learning_range_set", start=start, end=end),
            reply_markup=learning_order_keyboard()
        )
        logger.info(f"[LEARN] Custom range set {start}-{end} (mode=learning)")
    except Exception as e:
        logger.warning(f"[LEARN] Custom range parse error '{txt}' err={e}")
        await update.message.reply_text(t(lang, "learning_set_custom", count=total_questions))

async def handle_learning_order(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """
    –û–±–∏—Ä–∞—î–º–æ –ø–æ—Ä—è–¥–æ–∫ –ª–∏—à–µ –∫–æ–ª–∏ –º–∏ —É –Ω–∞–≤—á–∞–ª—å–Ω–æ–º—É —Ñ–ª–æ—É—ñ —ñ –í–ñ–ï –≤–∏–±—Ä–∞–Ω–∏–π –¥—ñ–∞–ø–∞–∑–æ–Ω.
    """
    if not _is_learning_flow(context) or "learning_range" not in context.user_data:
        logger.info("[LEARN] order choice outside learning flow ‚Äî ignore")
        return

    if "add_question" in context.user_data:
        logger.info(f"[LEARN] Skip order: add_question active user={update.effective_user.id}")
        return

    lang = context.bot_data.get("lang", "uk")
    choice = (update.message.text or "").strip()
    total_questions = context.user_data.get("total_questions", 0)

    logger.info(f"[LEARN] handle_learning_order user={update.effective_user.id} choice='{choice}' total={total_questions}")

    if choice in {"üîô –ù–∞–∑–∞–¥", "‚¨ÖÔ∏è –ù–∞–∑–∞–¥"}:
        await update.message.reply_text(
            "–û–±–µ—Ä–∏ –¥—ñ–∞–ø–∞–∑–æ–Ω:",
            reply_markup=learning_range_keyboard(total_questions)
        )
        logger.info("[LEARN] Back to range keyboard")
        return

    start, end = context.user_data.get("learning_range", (1, min(50, total_questions if total_questions else 1)))
    question_range = list(range(start - 1, end))

    if choice == "üî¢ –ü–æ –ø–æ—Ä—è–¥–∫—É":
        context.user_data["order"] = question_range
        order_type = "–ø–æ –ø–æ—Ä—è–¥–∫—É"
    elif choice == "üé≤ –í —Ä–æ–∑–¥—Ä—ñ–±":
        shuffled = question_range.copy()
        random.shuffle(shuffled)
        context.user_data["order"] = shuffled
        order_type = "–≤ —Ä–æ–∑–¥—Ä—ñ–±"
    else:
        await update.message.reply_text(t(lang, "learning_order_wrong"))
        logger.info("[LEARN] Wrong order choice")
        return

    # –°—Ç–∞–Ω —Å–µ—Å—ñ—ó
    context.user_data["mode"] = "learning"
    context.user_data["step"] = 0
    context.user_data["score"] = 0
    context.user_data["wrong_pairs"] = []
    context.user_data["current_streak"] = 0
    context.user_data["start_time"] = datetime.now()

    # –°–∫–∏–¥–∞—î–º–æ ¬´–∂–∏–≤–µ¬ª –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –ø–æ–ø–µ—Ä–µ–¥–Ω—ñ—Ö —Å–µ—Å—ñ–π
    context.user_data.pop("question_chat_id", None)
    context.user_data.pop("question_message_id", None)
    context.user_data.pop("question_message_type", None)

    await update.message.reply_text(
        t(lang, "learning_start", count=len(question_range), order=order_type),
        reply_markup=None
    )
    logger.info(f"[LEARN] Start learning: count={len(question_range)} order={order_type}")

    await send_current_question(update.effective_chat.id, context)

# ===================== –î–æ–ø–æ–º—ñ–∂–Ω–µ: –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è —Å–ø–æ—Å–æ–±—É –≤—ñ–¥–ø—Ä–∞–≤–∫–∏ =====================

def _decide_inline_kind_and_filename(media_type: str, path: str) -> tuple[str, str]:
    """
    –ù–∞ –æ—Å–Ω–æ–≤—ñ —Ç–∏–ø—É/—Ä–æ–∑—à–∏—Ä–µ–Ω–Ω—è –ø–æ–≤–µ—Ä—Ç–∞—î:
      kind ‚àà {'photo','animation','video','audio','document'}
      filename ‚Äî —É–∑–≥–æ–¥–∂–µ–Ω–µ —ñ–º‚Äô—è —Ñ–∞–π–ª—É –∑ –ø—Ä–∞–≤–∏–ª—å–Ω–∏–º —Ä–æ–∑—à–∏—Ä–µ–Ω–Ω—è–º
    """
    base = os.path.basename(path)
    stem, ext = os.path.splitext(base)
    ext_low = (ext or "").lower()

    if media_type == "image":
        if ext_low in _IMG_EXT_PHOTO:
            return "photo", f"{stem or 'img'}{ext_low or '.jpg'}"
        if ext_low in _IMG_EXT_ANIM:
            return "animation", f"{stem or 'anim'}{ext_low or '.gif'}"
        return "document", f"{stem or 'image'}{ext_low or '.bin'}"

    if media_type == "video":
        if ext_low in _VIDEO_INLINE:
            return "video", f"{stem or 'video'}{ext_low or '.mp4'}"
        return "document", f"{stem or 'video'}{ext_low or '.bin'}"

    if media_type == "audio":
        use_ext = ext_low if ext_low in _AUDIO_EXTS else ".mp3"
        return "audio", f"{stem or 'audio'}{use_ext}"

    return "document", f"{stem or 'file'}{ext_low or '.bin'}"

# ===================== –†–µ–Ω–¥–µ—Ä –ø–∏—Ç–∞–Ω—å =====================

async def send_current_question(chat_id, context, edit_from_query=None):
    """
    –ü–æ–∫–∞–∑—É—î –ø–æ—Ç–æ—á–Ω–µ –ø–∏—Ç–∞–Ω–Ω—è, –∑ —É—Ä–∞—Ö—É–≤–∞–Ω–Ω—è–º –ø—Ä–∞–≤–∏–ª –≤—ñ–¥–ø—Ä–∞–≤–∫–∏:
    - .mp4 ‚Üí video; —ñ–Ω—à—ñ –≤—ñ–¥–µ–æ ‚Üí document
    - .jpg/.jpeg/.png/.webp ‚Üí photo; .gif ‚Üí animation
    - audio (.mp3/.wav/.ogg/.m4a/.aac/.flac) ‚Üí audio
    - —è–∫—â–æ –º–µ–¥—ñ–∞ –Ω–µ–º–∞—î/–Ω–µ —á–∏—Ç–∞—î—Ç—å—Å—è ‚Äî placeholder —è–∫ photo
    """
    step = context.user_data.get("step", 0)
    order = context.user_data.get("order", [])
    questions = context.user_data.get("questions", [])

    logger.info(f"[LEARN] send_current_question step={step} total_steps={len(order)}")

    if step >= len(order):
        from .testing import show_results  # —Å–ø—ñ–ª—å–Ω–∏–π –ø—ñ–¥—Å—É–º–æ–∫
        logger.info("[LEARN] Finished learning session -> show_results")
        await show_results(chat_id, context)
        return

    q_index = order[step]
    context.user_data["current_q_index"] = q_index
    q = questions[q_index]

    progress = get_progress_bar(step + 1, len(order))
    caption = f"{progress}\n\n" + format_question_text(q)

    markup = build_options_markup(q_index, two_columns=True)

    media_type, path = _pick_media_for_question(q)

    # –Ø–∫—â–æ –Ω–µ–º–∞—î –º–µ–¥—ñ–∞ ‚Äî –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä
    if media_type == "none" or not path:
        data = _placeholder_png_bytes()
        bio = _bio_with_name(data, f"q{q_index+1}.png")
        new_kind = "photo"
        saved_kind = context.user_data.get("question_message_type")

        if edit_from_query is not None and saved_kind == new_kind:
            try:
                await edit_from_query.edit_message_media(
                    media=InputMediaPhoto(media=bio, caption=caption, parse_mode="HTML"),
                    reply_markup=markup
                )
                context.user_data["question_message_type"] = "photo"
                context.user_data["question_chat_id"] = edit_from_query.message.chat_id
                context.user_data["question_message_id"] = edit_from_query.message.message_id
                logger.info("[LEARN] Edited placeholder photo in-place")
                return
            except Exception as e:
                logger.debug("[LEARN] edit placeholder failed: %s", e)

        sent = await context.bot.send_photo(
            chat_id=chat_id, photo=bio, caption=caption, reply_markup=markup, parse_mode="HTML"
        )
        context.user_data["question_message_type"] = "photo"
        context.user_data["question_chat_id"] = sent.chat_id
        context.user_data["question_message_id"] = sent.message_id
        logger.info("[LEARN] Sent placeholder photo (new message)")
        return

    # –Ñ –º–µ–¥—ñ–∞ ‚Äî —á–∏—Ç–∞—î–º–æ
    data = await _load_file_bytes(path)
    if not data:
        data = _placeholder_png_bytes()
        bio = _bio_with_name(data, f"q{q_index+1}.png")
        sent = await context.bot.send_photo(
            chat_id=chat_id, photo=bio, caption=caption, reply_markup=markup, parse_mode="HTML"
        )
        context.user_data["question_message_type"] = "photo"
        context.user_data["question_chat_id"] = sent.chat_id
        context.user_data["question_message_id"] = sent.message_id
        logger.info("[LEARN] Media missing -> sent placeholder photo")
        return

    new_kind, fname = _decide_inline_kind_and_filename(
        "image" if media_type == "image" else media_type, path
    )
    saved_kind = context.user_data.get("question_message_type")

    # –°–ø—Ä–æ–±–∞ –≤—ñ–¥—Ä–µ–¥–∞–≥—É–≤–∞—Ç–∏ —ñ—Å–Ω—É—é—á–µ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è, —è–∫—â–æ —Ç–∏–ø –∑–±—ñ–≥–∞—î—Ç—å—Å—è
    if new_kind == saved_kind and edit_from_query is not None:
        try:
            if new_kind == "photo":
                media = InputMediaPhoto(_bio_with_name(data, fname), caption=caption, parse_mode="HTML")
            elif new_kind == "animation":
                media = InputMediaAnimation(_bio_with_name(data, fname), caption=caption, parse_mode="HTML")
            elif new_kind == "video":
                media = InputMediaVideo(_bio_with_name(data, fname), caption=caption, parse_mode="HTML")
            elif new_kind == "audio":
                media = InputMediaAudio(_bio_with_name(data, fname), caption=caption, parse_mode="HTML")
            else:
                media = InputMediaDocument(_bio_with_name(data, fname), caption=caption, parse_mode="HTML")

            await edit_from_query.edit_message_media(media=media, reply_markup=markup)
            context.user_data["question_message_type"] = new_kind
            context.user_data["question_chat_id"] = edit_from_query.message.chat_id
            context.user_data["question_message_id"] = edit_from_query.message.message_id
            logger.info("[LEARN] Edited media in-place (same type)")
            return
        except BadRequest as e:
            if "Message is not modified" in str(e):
                logger.debug("[LEARN] message not modified, ignore")
                return
            logger.debug("[LEARN] edit same-type failed: %s", e)
        except Exception as e:
            logger.debug("[LEARN] edit same-type failed: %s", e)

    # –ù–∞–¥—Å–∏–ª–∞—î–º–æ –Ω–æ–≤–µ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–æ–≥–æ —Ç–∏–ø—É
    bio = _bio_with_name(data, fname)
    if new_kind == "photo":
        sent = await context.bot.send_photo(
            chat_id, bio, caption=caption, reply_markup=markup, parse_mode="HTML"
        )
    elif new_kind == "animation":
        sent = await context.bot.send_animation(
            chat_id, bio, caption=caption, reply_markup=markup, parse_mode="HTML"
        )
    elif new_kind == "video":
        sent = await context.bot.send_video(
            chat_id, bio, caption=caption, reply_markup=markup, parse_mode="HTML"
        )
    elif new_kind == "audio":
        sent = await context.bot.send_audio(
            chat_id, bio, caption=caption, reply_markup=markup, parse_mode="HTML"
        )
    else:
        sent = await context.bot.send_document(
            chat_id, bio, caption=caption, reply_markup=markup, parse_mode="HTML"
        )

    context.user_data["question_message_type"] = new_kind
    context.user_data["question_chat_id"] = sent.chat_id
    context.user_data["question_message_id"] = sent.message_id
    logger.info("[LEARN] Sent new message with kind=%s", new_kind)
